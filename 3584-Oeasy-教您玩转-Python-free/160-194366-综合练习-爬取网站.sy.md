---
show: step
version: 1.0
enable_checker: true
---

# 爬取网站

## 回忆

- 上次深入了 xpath 中的元素选择
  - 可以根据元素层级关系选择
  - 也可以根据元素位置选择
  - 还可以根据属性具体值选择
  - 而且可以根据文本的值进行选择
  - 甚至开始使用通配符
- 我们来爬取一个真正的网站吧
  - 比如 oeasy.org
  - 怎么弄呢？🤔

### 下载网站

```
git clone http://gitee.com/overmind1980/oeasyorg.git
sudo cp -r oeasyorg /usr/share/nginx/html/
sudo nginx
firefox http://localhost/oeasyorg/index.html
```

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210902-1630587764363)

- 在浏览器里面能打开
- 并且观察到编码格式是`utf-8`
- 我的目标是把红框里面的菜单扒下来

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210903-1630651569966)

### 获取 xpath

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210902-1630587857006)

- 右键"爱情"
- 复制 xpath

### 修改

- 把原来的 get.py 进行修改

```
import requests
from lxml import etree
response = requests.get("http://localhost/oeasyorg/index2.html")
s_html = response.content.decode("utf-8")
et_html = etree.HTML(s_html)
et_target = et_html.xpath("/html/body/header/nav/ul/li/a")
for element in et_target:
    print(element.text)
```

- 特别注意要把下载到的字节序列
- 解码为 string
- 然后再送到 parse 里面分析

### 运行

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210902-1630588016510)

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210902-1630588074620)

- 运行成功
- 如果我想把链接地址拿到
- 应该怎么办？
- 去源头

### lxml

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210902-1630588320923)

- 找到 etree 节点之后
- 找到他的 attrib 属性
- 这个属性是一个 dict 字典
- 然后找到["href"]属性的值

### 地址

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210902-1630588541314)

```
import requests
from lxml import etree
response = requests.get("http://localhost/oeasyorg/index2.html")
s_html = response.content.decode("utf-8")
et_html = etree.HTML(s_html)
et_target = et_html.xpath("/html/body/header/nav/ul/li/a")
for element in et_target:
    print(element.text)
    attributes = element.attrib
    print(attributes["href"])
```

### 存入文件

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210902-1630588772241)

```
import requests
from lxml import etree
response = requests.get("http://localhost/oeasyorg/index2.html")
s_html = response.content.decode("utf-8")
et_html = etree.HTML(s_html)
et_target = et_html.xpath("/html/body/header/nav/ul/li/a")
for element in et_target:
    print(element.text)
    attributes = element.attrib
    print(attributes["href"])
```

- 目前存储的是相对链接
- 需要转化为绝对链接

### 绝对链接

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210902-1630589231614)
![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210902-1630589240273)

- 完成了链接字符串的切片和拼接

```
import requests
from lxml import etree
response = requests.get("http://oeasy.org/index.html")
s_html = response.content.decode("utf-8")
et_html = etree.HTML(s_html)
et_target = et_html.xpath("/html/body/header/nav/ul/li/a")
with open("urls.txt","wt") as f:
    for element in et_target:
        attributes = element.attrib
        f.write("http://oeasy.org/"+attributes["href"][1:]+"\n")
```

### 总结

- 这次真的爬了一个网站
  - oeasy.org
- 右键检查元素
  - 获取 xpath
- 爬取之后获得属性 href 的值
- 然后切片并拼接为绝对链接地址
- 并且存储到了 urls.txt 中
- 能把这些链接都爬一遍么？🤔
- 下次再说
