---
show: step
version: 1.0
enable_checker: true
---

# 爬取百度

## 回忆

- 这次真的爬了一个网站
  - oeasy.org
- 右键检查元素
  - 获取 xpath
- 爬取之后获得属性 href 的值
- 然后切片并拼接为绝对链接地址
- 并且把每一个链接都爬了一遍
- 能出去爬个百度么？🤔

### 确认上网

- 一般的实验楼注册会员是不能上 baidu 之类的网站的
- 想要爬取百度有两种解决办法
  - 花钱成为会员
  - 在自己能上网的机器上使用火狐和 python
- 想要爬百度
- 首先要确认能上百度

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635045425558)

### 准备环境

- 导入了该导入了包
- 然后发送请求
- 结果百度好像异常简单

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635045479631)

- 百度本身就是个大爬虫
- 他发现了我们是爬虫
- 结果就把我们给禁了 😰
- 那怎么办？😱

### 假装

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635046905973)

- 然后把这个 key-value 对写到 header 中

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047188733)

- 注意 headers 是一个字典
  - key-value 之间有冒号
  - key 和 value 都有双引号包裹
  - 冒号双引号都是半角的
- 请求中的协议是 https
- 好像可以得到正确的响应

### 生成 etree

- 这下把正确的响应放到 lxml 中进行解析
- 生成一棵 etree

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047598112)

- 但是得到的这一棵树
- 我怎样才能找到相应的内容呢
- 这就需要 xpath

### 找 xpath

- 找之前要确认登录状态
  - 我们这个是没有登陆的百度首页

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047760757)

- 右键左上角的新闻
  - 检查元素
- 可以看到他对应着 a 标签
- 后面的地图之类的也对应着 a 标签
- 如何得到 xpath 呢？

### 得到 xpath

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047839977)

- 右键元素可以找到他对应的 xpath
  - /html/body/div[1]/div[1]/div[3]/a[1]
  - 我们想要得到所有的 a 标签
  - /html/body/div[1]/div[1]/div[3]/a

### 筛选元素

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047975898)

- 我们可以得到一个 a 元素的列表
- 我们遍历这个列表

### 遍历列表

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635048067904)

- 如果我想把链接也输出
- 应该怎么办？

### 输出连接

- 先查一下文档

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635048399340)

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635048417860)

- 遍历完成
- 这很简单
- 我们再看看百度热搜

### 百度热搜

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635048555965)

- xpath 是
  - /html/body/div[1]/div[1]/div[5]/div/div/div[3]/ul/li[1]/a/span[2]
  - 通过观察
  - 相关的列表对应的 xpath 应该是
    - /html/body/div[1]/div[1]/div[5]/div/div/div[3]/ul/li/a/span[2]

### 进行遍历

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635048757888)

- 但是我如果想要同时输出具体链接呢？

### 重新构造列表

- span 在 a 里面
- 所以我们先把所有的 a 的列表拿到
- 然后再使用下表的方式找到 span 的 text

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635049094363)

- 还可以遍历最下面的链接吗？

### 最下面的

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635049252958)

- 这个好像比较简单
- 文字和链接都在 a 元素中

### xpath

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635049346923)

- a 元素在 p 元素中
- 所以把 p 元素的索引去掉
- /html/body/div[1]/div[1]/div[7]/div/p/a

### 遍历

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635049450518)

### 总结

- 这次爬了 baidu.com
- 找到了三组链接
- 然后分别遍历
- 还可以爬点什么？🤔
- 下次再说
