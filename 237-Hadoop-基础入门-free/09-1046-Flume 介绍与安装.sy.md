---
show: step
version: 1.0
enable_checker: true
---

# Flume 介绍与安装

## 实验介绍

本节实验将介绍日志收集系统 Flume。

**环境说明**

部署节点操作系统为 Ubuntu，防火墙和 SElinux 禁用，创建了一个 shiyanlou 用户并在系统根目录下创建 `/opt` 目录，用于存放 Hadoop 等组件运行包。因为该目录用于安装 hadoop 等组件程序，用户对 shiyanlou 必须赋予 rwx 权限（一般做法是 root 用户在根目录下创建 `/opt` 目录，并修改该目录拥有者为 shiyanlou(`chown –R shiyanlou:shiyanlou /opt`)。

**Hadoop 搭建环境：**

- 虚拟机操作系统：Ubuntu 64 位，4 核，16G 内存
- JDK：1.8.0_292 64 位
- Hadoop：2.9.2

#### 知识点

- Flume 架构
- Flume 管理方式
- Flume 安装与部署

## Flume 介绍

Flume 是 Cloudera 提供的日志收集系统，Flume 支持在日志系统中定制各类数据发送方，用于收集数据。同时，Flume 提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。Flume 是一个分布式、可靠和高可用的海量日志采集、聚合和传输的系统。

Flume 具有 Reliability、Scalability、Manageability 和 Extensibility 特点：

- `Reliability`：Flume 提供 3 种数据可靠性选项，包括 End-to-end、Store on failure 和 Best effort。其中 End-to-end 使用了磁盘日志和接受端 Ack 的方式，保证 Flume 接受到的数据会最终到达目的。Store on failure 在目的不可用的时候，数据会保持在本地硬盘。和 End-to-end 不同的是，如果是进程出现问题，Store on failure 可能会丢失部分数据。Best effort 不做任何 QoS 保证。
- `Scalability`：Flume 的 3 大组件：collector、master 和 storage tier 都是可伸缩的。需要注意的是，Flume 中对事件的处理不需要带状态，它的 Scalability 可以很容易实现。
- `Manageability`：Flume 利用 ZooKeeper 和 gossip，保证配置数据的一致性、高可用。同时，多 Master，保证 Master 可以管理大量的节点。
- `Extensibility`：基于 Java，用户可以为 Flume 添加各种新的功能，如通过继承 Source，用户可以实现自己的数据接入方式，实现 Sink 的子类，用户可以将数据写往特定目标，同时，通过 SinkDecorator，用户可以对数据进行一定的预处理。

### Flume 架构

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1046timestamp1433989979142.png)

上图的 Flume 的架构中最重要的抽象是 data flow（数据流），data flow 描述了数据从产生、传输、处理并最终写入目标的一条路径（在上图中，实线描述了 data flow）。Agent 用于采集数据，agent 是 flume 中产生数据流的地方，同时，agent 会将产生的数据流传输到 collector。对应的，collector 用于对数据进行聚合，往往会产生一个更大的流。

Flume 提供了从 console（控制台）、RPC（Thrift-RPC）、text（文件）、tail（UNIX tail）、syslog（syslog 日志系统，支持 TCP 和 UDP 等 2 种模式），exec（命令执行）等数据源上收集数据的能力。同时，Flume 的数据接受方，可以是 console（控制台）、text（文件）、dfs（HDFS 文件）、RPC（Thrift-RPC）和 syslogTCP（TCP syslog 日志系统）等。

其中，收集数据有 2 种主要工作模式，如下：

- `Push Sources`：外部系统会主动地将数据推送到 Flume 中，如 RPC、syslog。
- `Polling Sources`：Flume 到外部系统中获取数据，一般使用轮询的方式，如 text 和 exec。

注意，在 Flume 中，agent 和 collector 对应，而 source 和 sink 对应。source 和 sink 强调发送、接受方的特性（如数据格式、编码等），而 agent 和 collector 关注功能。

### Flume 管理方式

Flume Master 用于管理数据流的配置，如下图。

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1046timestamp1433990025003.png)

为了保证可扩展性，Flume 采用了多 Master 的方式。为了保证配置数据的一致性，Flume 引入了 ZooKeeper，用于保存配置数据，ZooKeeper 本身可保证配置数据的一致性和高可用，另外，在配置数据发生变化时，ZooKeeper 可以通知 Flume Master 节点。

Flume Master 间使用 gossip 协议同步数据。

## 安装部署 Flume

这一章节我们将正式开始讲解安装部署 Flume，分步骤进行。

### Flume 部署过程


通过下面命令启动 Hadoop 并通过 `jps` 查看进程：

```bash
cd /opt/hadoop-2.9.2/sbin
./start-all.sh
jps
```

**下载 Flume**

> **注：**当前实验环境 Flume 已经安装配置完成，下述安装步骤仅做参考，读者无序再重新配置。

可以到 apache 基金 flume 官网 `http://flume.apache.org/download.html`，选择镜像下载地址 `http://mirrors.hust.edu.cn/apache/flume/` 下载一个稳定版本，如下图所示下载 `flume-1.9.0-bin.tar.gz`：

![图片描述](https://doc.shiyanlou.com/courses/237/2505524/7eb369167323c0e74ba950ce8d6642fd-0)


```bash
# 下载 Flume-1.9.0
wget https://labfile.oss.aliyuncs.com/courses/237/apache-flume-1.9.0-bin.tar.gz
# 解压
tar -xzf apache-flume-1.9.0-bin.tar.gz
# 移动并重命名
mv apache-flume-1.9.0-bin /opt/flume-1.9.0
```

**设置 /etc/profile 参数**

编辑 `/etc/profile` 文件，声明 Flume 的 home 路径和在 path 加入 `bin` 的路径：

```bash
export FLUME_HOME=/opt/flume-1.9.0
export FLUME_CONF_DIR=$FLUME_HOME/conf
export PATH=$PATH:$FLUME_HOME/bin
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1046timestamp1433990089011.png)

使配置文件 `/etc/profile` 生效。

```bash
source /etc/profile
echo $PATH
```

**设置 flume-env.sh 配置文件**

在 `$FLUME_HOME/conf` 下复制改名 `flume-env.sh.template` 为`flume-env.sh`，修改 `conf/ flume-env.sh` 配置文件

```bash
cd /opt/flume-1.9.0/conf
cp flume-env.sh.template flume-env.sh
sudo vi flume-env.sh
```

修改配置文件内容：

```text
JAVA_HOME= /usr/lib/jvm/java-8-openjdk-amd64
JAVA_OPTS="-Xms100m -Xmx200m -Dcom.sun.management.jmxremote"
```

![图片描述](https://doc.shiyanlou.com/courses/237/2505524/cf3434eeb16f0061380974e1f6b786d9-0)

### 部署验证

**验证安装**

1. 修改 `flume-conf` 配置文件。

在 `$FLUME_HOME/conf` 目录下修改 `flume-conf.properties.template` 文件，复制并改名为 `flume-conf.properties`：

```bash
cd /opt/flume-1.9.0/conf
cp flume-conf.properties.template flume-conf.properties
sudo vi flume-conf.properties
```

修改 `flume-conf` 配置文件内容：

```text
# The configuration file needs to define the sources, the channels and the sinks.
# Sources, channels and sinks are defined per agent, in this case called 'a1'
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# For each one of the sources, the type is defined
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444

#The channel can be defined as follows.
a1.sources.r1.channels = c1
# Each sink's type must be defined
a1.sinks.k1.type = logger

#Specify the channel the sink should use
a1.sinks.k1.channel = c1

# Each channel's type is defined.
a1.channels.c1.type = memory
# Other config values specific to each type of channel(sink or source)
# can be defined as well
# In this case, it specifies the capacity of the memory channel
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1046timestamp1433990123186.png)

2. 在 flume 的安装目录 `/flume-1.9.0` 下运行：

```bash
cd /opt/flume-1.9.0
bin/flume-ng agent --conf conf --conf-file conf/flume-conf.properties --name a1 -Dflume.root.logger=INFO,console
```

![图片描述](https://doc.shiyanlou.com/courses/237/2505524/3bd0b118344e24089fdcb731f032d14f-0)

3. 再打开一个终端，输入如下命令：

```bash
telnet 127.0.0.1 44444
hello world
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1046timestamp1433990192967.png)

> 注：在 Ubuntu 运行 telnet 提示 "command not found"，使用 `sudo apt install telnet` 进行安装。

补充说明：由于该课程环境特殊，无法在同一页面开启多个终端。所以以下结果为示例，大家不需要在环境中进行操作。

4. 在原来的终端上查看，可以收到来自于 `telnet` 发出的消息：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1046timestamp1433990200396.png)

**测试收集日志到 HDFS**

1. 在 `$FLUME_HOME/conf` 目录下修改 `flume-conf.properties.template` 文件，复制并改名为 `flume-conf2.properties`：

```bash
cd /opt/flume-1.9.0/conf
cp flume-conf.properties.template flume-conf2.properties
sudo vi flume-conf2.properties
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1046timestamp1433990223625.png)

```text
a1.sources = r1
a1.sinks = k1
a1.channels = c1
a1.sources.r1.type = exec
a1.sources.r1.channels = c1
a1.sources.r1.command = tail -F /opt/hadoop-2.9.2/logs/hadoop-shiyanlou-namenode-b393a04554e1.log  # 这里需要根据实际环境中的数据进行填写
a1.sinks.k1.type = hdfs
a1.sinks.k1.channel = c1
a1.sinks.k1.hdfs.path = hdfs://localhost:9000/class12/out_flume
a1.sinks.k1.hdfs.filePrefix = events-
a1.sinks.k1.hdfs.round = true
a1.sinks.k1.hdfs.roundValue = 10
a1.sinks.k1.hdfs.roundUnit = minute
a1.sinks.k1.hdfs.rollSize = 4000000
a1.sinks.k1.hdfs.rollCount = 0
a1.sinks.k1.hdfs.writeFormat = Text
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.batchSize = 10
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
```

注意：上面的 `a1.sources.r1.command` 项配置的地址需要进入到 `/opt/hadoop-2.9.2/logs` 目录下进行查看，然后任意填写一个 log 文件名即可。

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1046timestamp1433990236998.png)

2. 在 flume 的安装目录 `/flume-1.9.0` 下运行：

```bash
cd /opt/flume-1.9.0
bin/flume-ng agent --conf conf --conf-file conf/flume-conf2.properties --name a1 -Dflume.root.logger=INFO,console
```

3. 不断收集 `log` 的数据写入 HDFS 中。

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1046timestamp1433990261958.png)

4. 查看 hdfs 中 `/class12/out_flume` 中的文件：

```bash
hadoop fs -ls /class12/out_flume
hadoop fs -cat /class12/out_flume/events-.1433921305493
```

![图片描述](https://doc.shiyanlou.com/courses/237/2505524/52244e707704d5463b2baae6041511f2-0)
