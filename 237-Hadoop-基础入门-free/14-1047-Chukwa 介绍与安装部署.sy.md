---
show: step
version: 1.0
enable_checker: true
---

# Chukwa 介绍与安装部署

## 实验介绍

本节实验将介绍 Chukwa 数据收集系统。

**环境说明**

> 注意：
>
> 本实验是对前述实验的延续，如果直接点“开始实验”进入则需要按实验 1 的方法配置并启动 hadoop。
>
> 实验使用的安装包、代码和数据均在 `/home/shiyanlou/install-pack` 目录下。

部署节点操作系统为 CentOS，防火墙和 SElinux 禁用，创建了一个 shiyanlou 用户并在系统根目录下创建 `/app` 目录，用于存放 Hadoop 等组件运行包。因为该目录用于安装 hadoop 等组件程序，用户对 shiyanlou 必须赋予 rwx 权限（一般做法是 root 用户在根目录下创建 `/app` 目录，并修改该目录拥有者为 shiyanlou(`chown –R shiyanlou:shiyanlou /app`)。

**Hadoop 搭建环境：**

- 虚拟机操作系统：CentOS 64 位，单核，1G 内存
- JDK：64 位
- Hadoop：1.1.2

#### 知识点

- Chukwa 架构
- Chukwa 组件说明
- Chukwa 安装与部署

## Chukwa 介绍

Chukwa 是一个开源的用于监控大型分布式系统的数据收集系统。这是构建在 hadoop 的 hdfs 和 map/reduce 框架之上的，继承了 hadoop 的可伸缩性和鲁棒性。Chukwa 还包含了一个强大和灵活的工具集，可用于展示、监控和分析已收集的数据。

### Chukwa 架构

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991104888.png/wm)

其中主要的组件为：

- `agents`：负责采集最原始的数据，并发送给 collectors。
- `adaptor`：直接采集数据的接口和工具，一个 agent 可以管理多个 adaptor 的数据采集。
- `collectors`：负责收集 agents 收送来的数据，并定时写入集群中
- `map/reduce jobs`：定时启动，负责把集群中的数据分类、排序、去重和合并。
- `hicc`：负责数据的展示。

### 组件说明

#### adaptors 和 agents

在每个数据的产生端（基本上是集群中每一个节点上），chukwa 使用一个 agent 来采集它感兴趣的数据，每一类数据通过一个 adaptor 来实现，数据的类型 (DataType) 在相应的配置中指定。

默认地，chukwa 对以下常见的数据来源已经提供了相应的 adaptor：命令行输出、log 文件和 httpSender 等等。这些 adaptor 会定期运行（比如每分钟读一次 df 的结果）或事件驱动地执行（比如 kernel 打了一条错误日志）。如果这些 adaptor 还不够用，用户也可以方便地自己实现一个 adaptor 来满足需求。

为防止数据采集端的 agent 出现故障，chukwa 的 agent 采用了所谓的 `watchdog` 机制，会自动重启终止的数据采集进程，防止原始数据的丢失。另一方面，对于重复采集的数据，在 chukwa 的数据处理过程中，会自动对它们进行去重。这样就可以对于关键的数据在多台机器上部署相同的 agent，从而实现容错的功能。

#### collectors

agents 采集到的数据，是存储到 hadoop 集群上的。hadoop 集群擅长于处理少量大文件，而对于大量小文件的处理则不是它的强项，针对这一点，chukwa 设计了 collector 这个角色，用于把数据先进行部分合并，再写入集群，防止大量小文件的写入。

另一方面，为防止 collector 成为性能瓶颈或成为单点，产生故障，chukwa 允许和鼓励设置多个 collector, agents 随机地从 collectors 列表中选择一个 collector 传输数据，如果一个 collector 失败或繁忙，就换下一个 collector。从而可以实现负载的均衡，实践证明，多个 collector 的负载几乎是平均的。

#### demux 和 archive

放在集群上的数据，是通过 map/reduce 作业来实现数据分析的。在 map/reduce 阶段，chukwa 提供了 demux 和 archive 任务两种内置的作业类型。

demux 作业负责对数据的分类、排序和去重。在 agent 一节中，我们提到了数据类型 (DataType) 的概念。由 collector 写入集群中的数据，都有自己的类型。demux 作业在执行过程中，通过数据类型和配置文件中指定的数据处理类，执行相应的数据分析工作，一般是把非结构化的数据结构化，抽取中其中的数据属性。由于 demux 的本质是一个 map/reduce 作业，所以我们可以根据自己的需求制定自己的 demux 作业，进行各种复杂的逻辑分析。chukwa 提供的 demux interface 可以用 java 语言来方便地扩展。

而 archive 作业则负责把同类型的数据文件合并，一方面保证了同一类的数据都在一起，便于进一步分析，另一方面减少文件数量，减轻 hadoop 集群的存储压力。

#### dbadmin

放在集群上的数据，虽然可以满足数据的长期存储和大数据量计算需求，但是不便于展示。为此，chukwa 做了两方面的努力：

- 使用 mdl 语言，把集群上的数据抽取到 mysql 数据库中，对近一周的数据，完整保存，超过一周的数据，按数据离当前时间长短作稀释，离当前越久的数据，所保存的数据时间间隔越长。通过 mysql 来作数据源，展示数据。
- 使用 hbase 或类似的技术，直接把索引化的数据在存储在集群上。

到 chukwa 0.4.0 版本为止，chukwa 都是用的第一种方法，但是第二种方法更优雅也更方便一些。

#### hicc

hicc 是 chukwa 的数据展示端的名称。在展示端，chukwa 提供了一些默认的数据展示 widget，可以使用“列表”、“曲线图”、“多曲线图”、“柱状图”、“面积图式展示一类或多类数据，给用户直观的数据趋势展示。而且，在 hicc 展示端，对不断生成的新数据和历史数据，采用 robin 策略，防止数据的不断增长增大服务器压力，并对数据在时间轴上“稀释”，可以提供长时间段的数据展示。

从本质上，hicc 是用 jetty 来实现的一个 web 服务端，内部用的是 jsp 技术和 javascript 技术。各种需要展示的数据类型和页面的局都可以通过简直地拖拽方式来实现，更复杂的数据展示方式，可以使用 sql 语言组合出各种需要的数据。如果这样还不能满足需求，不用怕，动手修改它的 jsp 代码就可以了。

## 安装部署 Chukwa

这一章节我们将正式开始讲解安装部署 Chukwa，分步骤进行。

### Chukwa 下载编译（实验楼已经提供编译包，该步骤不用执行）

**下载 Chukwa 源码**

通过 https://labfile.oss.aliyuncs.com/courses/237/chukwa-0.5.0-rc3.tar.gz 链接下载 chukwa-0.5.0 源码。

```bash
cd ~/install-pack
wget https://labfile.oss-internal.aliyuncs.com/courses/237/chukwa-0.5.0-rc3.tar.gz
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1515251543029.png/wm)

**编译 Chukwa**

解压下载源码包，生成 `chukwa-chukwa-0.5.0-rc3` 目录，使用如下命令编译，编译生成的安装包 chukwa-incubating-src-0.5.0.tar.gz 在 `$CHUKWA_HOME/target` 目录下。

```bash
tar –zxf chukwa-0.5.0-rc3.tar.gz
cd chukwa-chukwa-0.5.0-rc3
# 需要安装 maven
mvn package -Dmaven.test.skip=true
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1515251648662.png/wm)

若未编译，请直接下载已经编译的包到对应目录。

```bash
cd ~/install-pack
wget https://labfile.oss-internal.aliyuncs.com/courses/237/chukwa-incubating-0.5.0.tar.gz
```

### Chukwa 部署过程

**移动并解压**

上一步骤生成或者下载的编译包可以在 `/home/shiyanlou/install-pack` 目录中找到，解压该安装包并把该安装包复制到 `/app` 目录中。

```bash
cd ~/install-pack
tar -xzf chukwa-incubating-0.5.0.tar.gz
mv chukwa-incubating-0.5.0 /app/chukwa-0.5.0
```

**设置 /etc/profile 参数**

编辑 `/etc/profile` 文件，声明 chukwa 的 home 路径和在 path 加入 `bin/sbin` 的路径：

```bash
export CHUKWA_HOME=/app/chukwa-0.5.0
export CHUKWA_CONF_DIR=$CHUKWA_HOME/etc/chukwa
export PATH=$PATH:$CHUKWA_HOME/bin:$CHUKWA_HOME/sbin
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1515251902973.png/wm)

编译配置文件 `/etc/profile`，并确认生效。

```bash
source /etc/profile
echo $PATH
```

**将 Chukwa 文件复制到 Hadoop 中**

首先把 hadoop 配置目录中的 `log4j.properties` 和 `hadoop-metrics2.properties` 文件改名备份，然后把 chukwa 配置目录中的 `log4j.properties` 和 `hadoop-metrics2.properties` 文件复制到 hadoop 配置目录中。

```bash
cd /app/hadoop-1.1.2/conf
mv log4j.properties log4j.properties.bak
mv hadoop-metrics2.properties hadoop-metrics2.properties.bak
cp /app/chukwa-0.5.0/etc/chukwa/hadoop-log4j.properties ./log4j.propertie
cp /app/chukwa-0.5.0/etc/chukwa/hadoop-metrics2.properties ./
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1515251956261.png/wm)

**将 Chukwa 中 jar 复制到 Hadoop 中**

把 chukwa 中的 `chukwa-0.5.0-client.jar` 和 `json-simple-1.1.jar` 两个 jar 文件复制到 hadoop 中 `lib` 目录下：

```bash
cd /app/chukwa-0.5.0/share/chukwa
cp chukwa-0.5.0-client.jar /app/hadoop-1.1.2/lib
cp lib/json-simple-1.1.jar /app/hadoop-1.1.2/lib
ls /app/hadoop-1.1.2/lib
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1515251997557.png/wm)

**修改 chukwa-config.sh**

打开 `$CHUKWA_HOME/libexec/chukwa-config.sh` 文件：

```bash
cd /app/chukwa-0.5.0/libexec
sudo vi chukwa-config.sh
```

将 export CHUKWA_HOME='pwd -P \${CHUKWA_LIBEXEC}/..' 改为 chukwa 的安装目录：

```text
export CHUKWA_HOME=/app/chukwa-0.5.0
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1515252032406.png/wm)

**修改 chukwa-env.sh**

打开 `$CHUKWA_HOME/etc/chukwa/chukwa-env.sh` 文件。

```bash
cd /app/chukwa-0.5.0/etc/chukwa/
sudo vi chukwa-env.sh
```

配置 `JAVA_HOME` 和 `HADOOP_CONF_DIR` 等变量：

```text
# The java implementation to use.  Required.
export JAVA_HOME=/app/lib/jdk1.7.0_55
# Hadoop Configuration directory
export HADOOP_CONF_DIR=/app/hadoop-1.1.2/conf
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991325401.png/wm)

编译配置文件 `chukwa-env.sh` 使之生效。

**修改 collectors 文件**

打开 `$CHUKWA_HOME/etc/chukwa/collectors` 文件：

```bash
cd /app/chukwa-0.5.0/etc/chukwa/
sudo vi collectors
```

该配置指定哪台机器运行收集器进程，例如修改为 `http://hadoop:8080`，指定 hadoop 机器运行收集器进程。

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991387552.png/wm)

**修改 initial_adaptors 文件**

打开 `$CHUKWA_HOME/etc/chukwa/initial_adaptors` 文件：

```bash
cd /app/chukwa-0.5.0/etc/chukwa/
sudo vi initial_adaptors
```

> 可以使用默认配置（即不需要修改）。

为了更好显示测试效果这里添加新建的监控服务，监控 `/app/chukwa-0.5.0/` 目录下的 `testing` 文件变化情况：

```text
add filetailer.FileTailingAdaptor FooData /app/chukwa-0.5.0/testing 0
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991472448.png/wm)

建立被监控 `testing` 文件。

```bash
cd /app/chukwa-0.5.0
touch testing
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1515252118551.png/wm)

**修改 chukwa-collector-conf.xml 文件**

1. 打开 `$CHUKWA_HOME/etc/chukwa/chukwa-collector-conf.xml` 文件：

```bash
cd /app/chukwa-0.5.0/etc/chukwa/
sudo vi chukwa-collector-conf.xml
```

2. 启用 `chukwaCollector.pipeline` 参数：

   ```xml
   <property>
     <name>chukwaCollector.pipeline</name>
   	<value>org.apache.hadoop.chukwa.datacollection.writer.SocketTeeWriter,org.apache.hadoop.chukwa.datacollection.writer.SeqFileWriter</value>
   </property>
   ```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991524514.png/wm)

3. 注释 hbase 的参数（如果要使用 hbase 则不需要注释）。

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991545613.png/wm)

4. 指定 HDFS 的位置为 `hdfs://hadoop:9000/chukwa/logs`。

```xml
<property>
  <name>writer.hdfs.filesystem</name>
  <value>hdfs://hadoop:9000</value>
  <description>HDFS to dump to</description>
</property>
<property>
  <name>chukwaCollector.outputDir</name>
  <value>/chukwa/logs/</value>
  <description>Chukwa data sink directory</description>
</property>
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991588003.png/wm)

5. 确认默认情况下 collector 监听 8080 端口。

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991563082.png/wm)

**配置 Agents 文件**

打开 `$CHUKWA_HOME/etc/chukwa/agents` 文件。

```bash
cd /app/chukwa-0.5.0/etc/chukwa/
sudo vi agents
```

编辑 `$CHUKWA_CONF_DIR/agents` 文件，使用 hadoop。

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991618167.png/wm)

**修改 chukwa-agent-conf.xml 文件**

打开 `$CHUKWA_HOME/etc/chukwa/chukwa-agent-conf.xml` 文件。

```bash
cd /app/chukwa-0.5.0/etc/chukwa/
sudo vi chukwa-agent-conf.xml
```

`$CHUKWA_CONF_DIR/chukwa-agent-conf.xml` 文件维护了代理的基本配置信息，其中最重要的属性是集群名，用于表示被监控的节点，这个值被存储在每一个被收集到的块中，用于区分不同的集群，如设置 cluster 名称：`cluster="chukwa"` ，使用默认值即可：

```xml
<property>
    <name>chukwaAgent.tags</name>
    <value>cluster="chukwa"</value>
    <description>The cluster's name for this agent</description>
</property>
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991637920.png/wm)

### Chukwa 部署验证

配置本机主机名为 hadoop，sudo 时需要输入 shiyanlou 用户的密码。将 hadoop 添加到最后一行的末尾。

```bash
sudo vim /etc/hosts
# 将hadoop添加到最后一行的末尾，修改后类似：（使用 tab 键添加空格）
# 172.17.2.98 f738b9456777 hadoop
ping hadoop
```

**启动 Chukwa**

分别启动如下进程：

1. 启动 hadoop：

   ```bash
   cd /app/hadoop-1.1.2/bin
   ./start-all.sh
   jps
   ```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991659648.png/wm)

2. 启动 chukwa：

   ```bash
   cd /app/chukwa-0.5.0/sbin
   ./start-chukwa.sh
   ```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1515252220459.png/wm)

使用 `jps` 查看启动状态：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid600404labid1047timestamp1552301779120.png/wm)

使用 `telnet` 查看 agent 启动情况：

```bash
telnet hadoop 9093
telnet>list
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991701396.png/wm)

在这里，如果长时间没有其他命令数据输入，linux 会自动关闭相应的连接从而提示 `Connection closed by foreign host.`。

**准备日志数据文件和添加数据脚本**

1. 在 `/app/chukwa-0.5.0/testdata/` 目录下创建 `weblog` 文件，内容如下：

   ```bash
   cd /app/chukwa-0.5.0
   mkdir testdata && cd testdata
   vi weblog
   ```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991733915.png/wm)

数据如下：

```text
220.181.108.151  [31/Jan/2012:00:02:32] "GET /home.php?mod=space"
208.115.113.82   [31/Jan/2012:00:07:54] "GET /robots.txt"
220.181.94.221   [31/Jan/2012:00:09:24] "GET /home.php?mod=spacecp"
112.97.24.243    [31/Jan/2012:00:14:48] "GET /data/common.css?AZH HTTP/1.1"
112.97.24.243    [31/Jan/2012:00:14:48] "GET /data/auto.css?AZH HTTP/1.1"
112.97.24.243    [31/Jan/2012:00:14:48] "GET /data/display.css?AZH HTTP/1.1"
220.181.108.175  [31/Jan/2012:00:16:54] "GET /home.php"
220.181.94.221   [31/Jan/2012:00:19:15] "GET /?72 HTTP/1.1" 200 13614 "-"
218.5.72.173     [31/Jan/2012:00:21:39] "GET /forum.php?tid=89 HTTP/1.0"
65.52.109.151    [31/Jan/2012:00:24:47] "GET /robots.txt HTTP/1.1"
220.181.94.221   [31/Jan/2012:00:26:12] "GET /?67 HTTP/1.1"
218.205.245.7    [31/Jan/2012:00:27:16] "GET /forum-58-1.html HTTP/1.0"
```

2. 在 `/app/chukwa-0.5.0/testdata/` 目录下创建 `weblogadd.sh` 执行脚本，该脚本执行往 `testing` 文件添加 `weblog` 数据：

```bash
cd /app/chukwa-0.5.0/testdata/
vi weblogadd.sh
```

内容为：

```text
cat /app/chukwa-0.5.0/testdata/weblog >> /app/chukwa-0.5.0/testing
```

**查看 HDFS 的文件**

启动 chukwa 的 agents 和 collector，然后运行 `weblogadd.sh` 脚本，往 weblog 文件中添加数据，最后查看 HDFS 的 `/chukwa/logs` 目录下监听生成的数据文件：

```bash
cd /app/chukwa-0.5.0/testdata
sudo sh ./weblogadd.sh
hadoop fs -ls /chukwa/logs
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1047timestamp1433991791733.png/wm)
